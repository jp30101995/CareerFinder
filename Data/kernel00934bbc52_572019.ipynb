{"cells":[{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load in \n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\nfrom surprise import NMF\nfrom surprise import KNNWithMeans\nfrom surprise import accuracy\nfrom surprise.model_selection import KFold\nfrom surprise import SVD, SVDpp\nfrom surprise import Dataset\nfrom surprise.model_selection import cross_validate, train_test_split\nfrom surprise import Reader\n# Input data files are available in the \"../input/\" directory.\n# For example, running this (by clicking run or pressing Shift+Enter) will list the files in the input directory\nfrom surprise import KNNBasic\nimport matplotlib.pyplot as plt\nfrom sklearn.neighbors import NearestNeighbors\nimport os\nimport json\nprint(os.listdir(\"../input\"))\n\n# Any results you write to the current directory are saved as output.","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"collapsed":true},"cell_type":"code","source":"data_df = pd.read_csv(\"../input/hack019.csv\")\ndata_df.head()\ndata_df['ids'] = data_df['LearnerID'].map(str) + '-' + data_df['MasterYearName'] + '-' + data_df['MasterSubjectName'] \ndata_df.head()\nreader = Reader(rating_scale=(0, 100))\ndata = Dataset.load_from_df(data_df[['ids', 'MasterSubjectName', 'Points.1']], reader)\nalgo = SVD()\n# Run 5-fold cross-validation and print results.\ncross_validate(algo, data, measures=['RMSE', 'MAE'], cv=15, verbose=True)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"collapsed":true},"cell_type":"code","source":"learner_id = 1001\n\ndf = data_df.pivot_table(index = ['LearnerID'], values = 'Points.1', columns = 'MasterSubjectName').fillna(0)\ndf = df.reset_index() \n\ntest= df[df[\"LearnerID\"] == learner_id]\n# test = test.drop('LearnerID', axis=1)\n\nmodel_knn = NearestNeighbors(metric='cosine', algorithm='brute', n_neighbors=5, n_jobs=-1)\nmodel_knn.fit(df)\nvalues, indexes = model_knn.kneighbors(test.values.reshape(1,-1))\nsimilar_leaners = dict(zip(indexes[0], values[0]))\n\nsorted_leaners = [(k, similar_leaners[k]) for k in sorted(similar_leaners, key=similar_leaners.get, reverse=True)]\n\nindex_arr = []\nvalues_arr = []\nfor l in sorted_leaners:\n    index_arr.append(l[0])\n    values_arr.append(l[1])\n    \n    \nsimilar_learners_df = df.loc[index_arr, :]\n\nsimilar_learners_df['similarity'] = values_arr\ntest['similarity'] = 1\nsimilar_learners_df.append(test)\nsimilar_learners_df    \n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"learner_id = 2058\ndata = pd.read_csv(\"../input/hack019.csv\")\nlearner_data = data[data[\"LearnerID\"] == learner_id]\n\ndata['year'] = data['MasterYearName'].str.slice(5)\ndata['year'] = pd.to_numeric(data['year'], errors='coerce').fillna(0).astype(np.int64)\n\npast_data = data[(data['year'] < 3) & (data['year'] != 0) & (data['LearnerID'] != learner_id)]\n\ndf = past_data.pivot_table(index = ['LearnerID'], values = 'Points.1', columns = 'MasterSubjectName').fillna(0)\ndf = df.reset_index() \n\nlearner_pivot = learner_data.pivot_table(index = ['LearnerID'], values = 'Points.1', columns = 'MasterSubjectName').fillna(0)\nlearner_pivot = learner_pivot.reset_index()\n\n# test= df[df[\"LearnerID\"] == learner_id]\n# test = test.drop('LearnerID', axis=1)\nfinal_pivot = pd.concat([learner_pivot, df], ignore_index=False, sort=True).fillna(0)\nfinal_pivot[final_pivot[\"LearnerID\"] == learner_id]\n\n\nmodel_knn = NearestNeighbors(metric='cosine', algorithm='brute', n_neighbors=5, n_jobs=-1)\nmodel_knn.fit(df)\nvalues, indexes = model_knn.kneighbors(final_pivot[final_pivot[\"LearnerID\"] == learner_id].values.reshape(1,-1))\nsimilar_leaners = dict(zip(indexes[0], values[0]))\n\nfinal_learner_pivot = final_pivot[final_pivot[\"LearnerID\"] == learner_id]\n\nsorted_leaners = [(k, similar_leaners[k]) for k in sorted(similar_leaners, key=similar_leaners.get, reverse=True)]\n\nindex_arr = []\nvalues_arr = []\nfor l in sorted_leaners:\n    index_arr.append(l[0])\n    values_arr.append(l[1])\n    \n    \nsimilar_learners_df = df.loc[index_arr, :]\n\nsimilar_learners_df['similarity'] = values_arr\nfinal_learner_pivot['similarity'] = 1\nsimilar_learners_df = pd.concat([similar_learners_df,final_learner_pivot], ignore_index=False, sort=False).fillna(0) \nsimilar_learners_df \n\n\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"data[(data['year'] == 3) & (data['year'].isin(similar_learners_df['LearnerID']))]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df = df.reset_index() \ndf.head()\ntest.shape\n\ntest= df[df[\"LearnerID\"] == 1000]\n\ntest = test.drop('LearnerID', axis=1)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"data_df[\"BPoints\"] = data_df[\"Points.1\"] / 10\ndata_df[\"BPoints\"] = data_df[\"BPoints\"].astype(int)\n\n# bins = [0, 20, 40, 60, , 50, 100]\n# labels = [1,2,3,4,5,6]\n# df['binned'] = pd.cut(df['percentage'], bins=bins, labels=labels)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"reader = Reader(rating_scale=(0, 10))\ndata = Dataset.load_from_df(data_df[['ids', 'MasterSubjectName', 'BPoints']], reader)\nalgo = SVD()\n# Run 5-fold cross-validation and print results.\ncross_validate(algo, data, measures=['RMSE', 'MAE'], cv=5, verbose=True)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"collapsed":true},"cell_type":"code","source":"# sim_options = {'name': 'pearson_baseline'}\n# algo = KNNBasic(k=40, min_k=1, sim_options=sim_options)\ntot_clusters = int(len(df_nmf[\"uid\"].unique()) / 10) + 1\nsim_options = {'name': 'pearson_baseline',\n               'user_based': False  # compute  similarities between items\n               }\nalgo = KNNBasic(k=tot_clusters, min_k=1, sim_options=sim_options)\ntrainset, testset = train_test_split(data, test_size=.25)\npredictions = algo.fit(trainset).test(testset)\ndf_nmf = pd.DataFrame(predictions) #predictions     \naccuracy.rmse(predictions, verbose=True)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"algo.get_neighbors(5, k=10)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df_nmf.fillna('')\ncluster = []\nfor index, row in df_nmf.iterrows():\n    if \"actual_k\" in row[\"details\"]:\n        cluster.append(row[\"details\"][\"actual_k\"])\n    else:\n        cluster.append(0)\ndf_nmf[\"cluster\"] = cluster","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df_nmf[df_nmf[\"cluster\"] == 1]\ndf_nmf[\"cluster\"].hist()\nplt.hist(df_nmf[\"cluster\"], bins= 50)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"algo = NMF()\n# Run 5-fold cross-validation and print results.\ncross_validate(algo, data, measures=['RMSE', 'MAE'], cv=5, verbose=True)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"collapsed":true},"cell_type":"code","source":"kf = KFold(n_splits=5)\nalgo = NMF()\n\n#trainset, testset = train_test_split(data, test_size=.25)\nfor trainset, testset in kf.split(data):\n\n    # train and test algorithm.\n    algo.fit(trainset)\n    predictions = algo.test(testset)\n\n    # Compute and print Root Mean Squared Error\n    accuracy.rmse(predictions, verbose=True)\n\nalgo = SVD()\n\n#trainset, testset = train_test_split(data, test_size=.25)\nfor trainset, testset in kf.split(data):\n\n    # train and test algorithm.\n    algo.fit(trainset)\n    predictions = algo.test(testset)\n\n    # Compute and print Root Mean Squared Error\n    accuracy.rmse(predictions, verbose=True)\n\nalgo = SVDpp()\n\n#trainset, testset = train_test_split(data, test_size=.25)\nfor trainset, testset in kf.split(data):\n\n    # train and test algorithm.\n    algo.fit(trainset)\n    predictions = algo.test(testset)\n\n    # Compute and print Root Mean Squared Error\n    accuracy.rmse(predictions, verbose=True)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"algo = NMF()\ntrainset, testset = train_test_split(data, test_size=.25)\npredictions = algo.fit(trainset).test(testset)\ndf_nmf = pd.DataFrame(predictions) #predictions     \naccuracy.rmse(predictions, verbose=True)\n\nalgo = SVD()\ntrainset, testset = train_test_split(data, test_size=.25)\npredictions = algo.fit(trainset).test(testset)\ndf_svd = pd.DataFrame(predictions) #predictions    \naccuracy.rmse(predictions, verbose=True)\n\nalgo = SVDpp()\ntrainset, testset = train_test_split(data, test_size=.25)\npredictions = algo.fit(trainset).test(testset)\naccuracy.rmse(predictions)\naccuracy.rmse(predictions, verbose=True)\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"algo = SVD()\ntrainset, testset = train_test_split(data, test_size=.25)\npredictions = algo.fit(trainset).test(testset)\ndf_svd = pd.DataFrame(predictions) #predictions    \naccuracy.rmse(predictions, verbose=True)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df_svd.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# toy_story_inner_id = algo.trainset.to_inner_iid(toy_story_raw_id)\n\n# Retrieve inner ids of the nearest neighbors of Toy Story.\ntoy_story_neighbors = algo.get_neighbors(toy_story_inner_id, k=10)","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"name":"python","version":"3.6.4","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat":4,"nbformat_minor":1}